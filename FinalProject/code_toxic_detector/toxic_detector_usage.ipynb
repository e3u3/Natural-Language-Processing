{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toxicDetector import *\n",
    "from sentiment_new import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_useful_words(n,fea_names,coeffs):\n",
    "    '''\n",
    "    get importtant words from feature names given cls.coefficients\n",
    "\n",
    "    Args:\n",
    "        fea_names = sentiment.count_vect.get_feature_names()\n",
    "        coeffs = cls.coef_[0]\n",
    "    Return:\n",
    "        List of important words\n",
    "\n",
    "    '''\n",
    "    assert (n%2==0) and isinstance(n,int)\n",
    "    k=int(n/2)\n",
    "    sortword =np.argsort(coeffs)\n",
    "    top_k= sortword[-k:]\n",
    "    bottom_k=sortword[:k]\n",
    "    toxic_words=[]\n",
    "    nontoxic_words=[]\n",
    "    for i in top_k:\n",
    "        toxic_words.append(fea_names[i])\n",
    "\n",
    "    for i in bottom_k:\n",
    "        nontoxic_words.append(fea_names[i])\n",
    "\n",
    "    return toxic_words , nontoxic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data\n",
      "-- train data\n",
      "training dataset amount: 165496\n",
      "toxic in train set: 16098  (9.73%)\n",
      "non-toxic in train set : 149398\n",
      "-- dev data\n",
      "dev dataset amount: 10560 \n",
      "toxic in dev set : 1065  (10.09%)\n",
      "non-toxic in dev set : 9495  \n",
      "finished reading data\n",
      "start training data\n",
      "Classifier trained\n",
      "shape of coef_pre: (1550282,)\n",
      "________USEFUL WORDS_________\n",
      "toxic word list:  ['you you', 'grow', 'yourself', 'hypocrite', 'balls', 'jews', 'an asshole', 'piece', 'are an', 'blah', 'stop being', 'garbage', 'assholes', 'troll', 'spam', 'your', 'don be', 'mother', 'lies', 'stupidity', 'bunch of', 'the hell', 'piece of', 'morons', 'face', 'dumbass', 'and you', 'mouth', 'fuckin', 'scum', 'bunch', 'you suck', 'retard', 'fucker', 'bloody', 'little', 'piss', 'of shit', 'you are', 'dirty', 'disgusting', 'pussy', 'me you', 'homosexual', 'shut up', 'nigger', 'ridiculous', 'fucked', 'like you', 'wtf', 'what the', 'fuck off', 'sick', 'idiotic', 'kill', 'fag', 'an idiot', 'jerk', 'fat', 'off', 'retarded', 'racist', 'you re', 'sucks', 'talk page', 'die', 'sex', 'bastard', 'damn', 'liar', 'nazi', 'fool', 'ignorant', 'the fuck', 'shut', 'loser', 'fuck you', 'cock', 'penis', 'hate', 'dumb', 'moron', 'pathetic', 'faggot', 'idiots', 'gay', 'hell', 'cunt', 'dick', 'asshole', 'bullshit', 'bitch', 'crap', 'suck', 'idiot', 'ass', 'shit', 'stupid', 'fucking', 'fuck']\n",
      "nontoxic word list:  ['thanks', 'talk', 'utc', 'redirect', 'sorry', 'redirect talk', 'thank you', 'hi', 'thank', 'agree', 'please', 'yes', 'cheers', 'ok', 'best', 'support', 'template', 'section', 'wikiproject', 'may', 'request', 'welcome', 'references', 've', 'check', 'category', 'wp', 'sources', 'source', 'barnstar', 'reply', 'could', 'removed', 'question', 'regards', 'consensus', 'needs', 'new', 'above', 'sure', 'looks', 'image', 'note', 'list', 'deletion', 'see', 'thanks for', 'added', 'cool', 'happy', 'case', 'pov', 'report', 'considered', 'to get', 'help', 'fine', 'under', 'perhaps', 'saw', 'appreciate', 'need', 'work', 'discussion', 'mention', 'hello', 'main', 'add', 'further', 'correct', 'merge', 'at', 'articles', 'comments', 'article', 'great', 'well', 'isn', 'seems', 'name', 'disagree', 'better', 'review', 'interested', 'version', 'fixed', 'to me', 'moved', '2005', 'changed', 'also', 'for the', 'for your', 'mentioned', 'does', 'rfc', 'two', 'class', 'is it', 'should']\n",
      "start evaluating\n",
      "  Accuracy on dev data  is: 0.9493371212121212\n",
      "finished evaluation\n",
      "Accuracy before using stopwords: 0.9493371212121212\n",
      "time used: 2047.5632650852203\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "print(\"Reading data\")\n",
    "maxdf = 0.32\n",
    "mindf = 1\n",
    "sentiment = sentimentinterface.read_files( min_df = mindf, max_df = maxdf)\n",
    "solve_name = 'sag'\n",
    "penalty = 'l2'\n",
    "print(\"finished reading data\")\n",
    "print(\"start training data\")\n",
    "cls = train_classifier(sentiment.trainX, sentiment.trainy, penalty = penalty, solver = solve_name)\n",
    "print(\"Classifier trained\")\n",
    "\n",
    "coef_now = cls.coef_[0]\n",
    "fea_names = sentiment.count_vect.get_feature_names()\n",
    "coeffs = cls.coef_[0]\n",
    "print('shape of coef_pre:' ,coef_now.shape)\n",
    "\n",
    "toxic_words, nontoxic_words = get_useful_words(200,fea_names,coef_now)\n",
    "print(\"________USEFUL WORDS_________\")\n",
    "print(\"toxic word list: \", toxic_words)\n",
    "print(\"nontoxic word list: \", nontoxic_words)\n",
    "\n",
    "\n",
    "print(\"start evaluating\")\n",
    "acc = evaluate(sentiment.devX, sentiment.devy, cls, 'dev data')\n",
    "print(\"finished evaluation\")\n",
    "print('Accuracy before using stopwords: {}'.format(acc))\n",
    "\n",
    "time_elapsed = time.time() - time_start\n",
    "print(\"time used: {}\".format(time_elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = get_stopwords(1000000,fea_names,coef_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing by random input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go to the hell you son of bitch : 0.9389627121725953   (toxic) \n",
      " i love u : 0.27079326303185913   (peace) \n",
      "you are so annoying : 0.4810936704028729   (peace) \n",
      "I don't really like you : 0.43936569993927754   (peace) \n",
      "how do you think about Eric : 0.2448487309278115   (peace) \n",
      "I want to kick him : 0.3268353833919887   (peace) \n",
      " : 0.3121504881712093   (peace) \n"
     ]
    }
   ],
   "source": [
    "input_string = [\"go to the hell you son of bitch\",\" i love u\",'you are so annoying','I don\\'t really like you','how do you think about Eric','I want to kick him',\"\"]\n",
    "input_vect = sentiment.count_vect.transform(input_string)\n",
    "probs = cls.predict_proba(input_vect)\n",
    "label = cls.predict(input_vect)\n",
    "label_sentiment = sentiment.le.inverse_transform(label)\n",
    "\n",
    "label_list = [x[1] for x in probs]\n",
    "\n",
    "for i in range(len(input_string)):\n",
    "    print('{} : {}   ({}) '.format(input_string[i], label_list[i], label_sentiment[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1550282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.06276225559135505"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(fea_names))\n",
    "coef_now[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "'''\n",
    "f = open('train.tsv', 'w')\n",
    "for i in range(len(data_train)):\n",
    "    f.write('peace' if labels_train[i] is False else 'toxic')\n",
    "    f.write(\"\\t\")\n",
    "    f.write(data_train[i])\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "\n",
    "f = open('dev.tsv', 'w')\n",
    "for i in range(len(data_dev)):\n",
    "    f.write('peace' if labels_dev[i] is False else 'toxic')\n",
    "    f.write(\"\\t\")\n",
    "    f.write(data_dev[i])\n",
    "    f.write(\"\\n\")\n",
    "f.close()\n",
    "'''\n",
    "\n",
    "f = open('train.csv', 'a')\n",
    "writer = csv.writer(f)\n",
    "for i in range(len(data_train)):\n",
    "    l = 'peace' if labels_train[i] is False else 'toxic'\n",
    "    text = data_train[i]\n",
    "    row = [l,text]\n",
    "    writer.writerow(row)\n",
    "f.close()\n",
    "\n",
    "f = open('dev.csv', 'a')\n",
    "writer = csv.writer(f)\n",
    "for i in range(len(data_dev)):\n",
    "    l = 'peace' if labels_dev[i] is False else 'toxic'\n",
    "    text = data_dev[i]\n",
    "    row = [l,text]\n",
    "    writer.writerow(row)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save the cls object into pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "output = open(\"basic_toxicDetector.pkl\",'wb')\n",
    "pickle.dump(cls, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_input = open(\"basic_toxicDetector.pkl\", 'rb')\n",
    "cls1 = pickle.load(pkl_input)\n",
    "pkl_input.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(fname):\n",
    "    data = []\n",
    "    labels = []\n",
    "    f = open(fname, 'r')\n",
    "    #readCSV = csv.reader(f, delimiter = ',')\n",
    "    \n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        labels.append(row[0])\n",
    "        data.append(row[1])\n",
    "    return data, labels\n",
    "\n",
    "d, l = read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
